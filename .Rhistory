keep_fa <- data.frame(df_test) # subsetting
keep_fa <- data.frame(unlist(keep_fa$family))
names(keep_fa) <- 'Family'
keep <- cbind(keep_ap, keep_sp, keep_gen, keep_fa)
dat.ices <- subset(dat.ices, dat.ices$AphiaID %in% keep_ap$AphiaID)
dat.ices <- left_join(dat.ices, keep, by='AphiaID')
dat.ices$Species <- dat.ices$ScientificName
dat.ices$ScientificName <- NULL
survey <- dat.ices
survey <- survey %>%
select(Survey, HaulID, StatRec, Year, Month, Quarter, Season, ShootLat, ShootLong, HaulDur, Area.swept, Area.doors,
Gear, Depth, SBT, SST,AphiaID, Family, Genus, Species, CatIdentifier, numcpue, wtcpue, numh, wgth, num, wgt, Length, numlencpue, numlenh)
### Code to integrate from Anna Rindorf on species bycatch corrections
survey <- data.frame(survey)
survey <- survey %>%
mutate(Species = recode(Species,'Dipturus batis'='Dipturus','Dipturus flossada'='Dipturus',
'Dipturus batis-complex'='Dipturus','Dipturus intermedia'='Dipturus',
'Dipturus'='Dipturus','Liparis montagui'='Liparis',
'Liparis liparis'='Liparis','Liparis liparis liparis'='Liparis',
'Chelon aurata'='Chelon','Chelon ramada'='Chelon',
'Mustelus mustelus/asterias'='Mustelus','Mustelus'='Mustelus',
'Mustelus mustelus'='Mustelus','Mustelus asterias'='Mustelus',
'Alosa'='Alosa','Alosa alosa'='Alosa','Alosa fallax'='Alosa',
'Argentina'='Argentina','Argentinidae'='Argentina',
'Argentina silus'='Argentina','Argentina sphyraena'='Argentina',
'Callionymus reticulatus'='Callionymus','Callionymus maculatus'='Callionymus',
'Ciliata mustela'='Ciliata','Ciliata septentrionalis'='Ciliata',
'Gaidropsarus'='Gaidropsarus','Gaidropsaurus macrophthalmus'='Gaidropsarus',
'Gaidropsaurus mediterraneus'='Gaidropsarus','Gaidropsaurus vulgaris'='Gaidropsarus',
'Sebastes'='Sebastes','Sebastes norvegicus'='Sebastes','Sebastes mentella'='Sebastes',
'Sebastes marinus'='Sebastes','Syngnathus'='Syngnatus',
'Syngnathus rostellatus'='Syngnatus','Syngnathus acus'='Syngnatus',
'Syngnathus typhle'='Syngnatus','Nerophis ophidion'='Syngnatus',
'Pomatoschistus'='Pomatoschistus','Pomatoschistus microps'='Pomatoschistus',
'Pomatoschistus minutus'='Pomatoschistus','Pomatoschistus pictus'='Pomatoschistus',
'Lesueurigobius'='Gobius','Gobius cobitis'='Gobius','Gobius niger'='Gobius',
'Leusueurigobius friesii'='Gobius','Neogobius melanostomus'='Gobius',
'Neogobius'='Gobius'))
##########################################################################################
#### ADD GEAR EFFICIENCY CORRECTIONS
##########################################################################################
#source('scripts - data processing/Merge_names_walker-catchability_with_datras.R')
load("traits and species/Names_DATRAS_Walker_match.Rdata")
# load all aphiaID of cephalopods
ceph_q <- data.frame(AphiaID = ceph$AphiaID,Species=NA,Genus=NA,Family=NA,q_group = "GR4")
q_names <- rbind(q_names,ceph_q)
tail(q_names)
uniquq(q_names$q_group)
unique(q_names$q_group)
##########################################################################################
#### ADD GEAR EFFICIENCY CORRECTIONS
##########################################################################################
#source('scripts - data processing/Merge_names_walker-catchability_with_datras.R')
load("traits and species/Names_DATRAS_Walker_match.Rdata")
# load all aphiaID of cephalopods
ceph_q <- data.frame(AphiaID = ceph$AphiaID,Species=NA,Genus=NA,Family=NA,q_group = "GRP4")
q_names <- rbind(q_names,ceph_q)
conversions <- read.csv("data/Walkeretal_2017_supp/EfficiencyTab.csv",header=T,sep=",")
conversions <- subset(conversions,conversions$Gear =="GOV")
# combine q_group/q_species code with survey
survey <- cbind(survey,q_names[match(survey$AphiaID,q_names$AphiaID),c("q_group")])
colnames(survey)[ncol(survey)] <- "Code"
# get unique length (q's are length based) and code
uni <- survey %>%
distinct(Code, Length)
uni <- left_join(uni, conversions, by = "Code") %>%
mutate(Diff = abs(Length.x + 0.02 -Length.y)) %>%   # added 0.02 to avoid ending in the middle
group_by(Length.x,Code) %>%
filter(Diff == min(Diff))
uni$uni <- paste(uni$Code,uni$Length.x)
survey$uni <- paste(survey$Code,survey$Length)
# and combine to get efficiency
survey <- cbind(survey,uni[match(survey$uni,uni$uni),c("Efficiency")])
colnames(survey)[ncol(survey)] <- "q_eff"
survey$q_eff <- ifelse(survey$q_eff<0.01, 0.01,survey$q_eff) # to avoid too high corrections at the boundaries of the GAM model (Walker) -- check sensitivity!!
survey <- survey %>%
mutate(numlencpue_q    = numlencpue/q_eff,
numlenh_q       = numlenh/q_eff) %>%
select(Survey, HaulID, StatRec, Year, Month, Quarter, Season, ShootLat, ShootLong, HaulDur, Area.swept, Area.doors,
Gear, Depth, SBT, SST, AphiaID, Family, Genus, Species, CatIdentifier, numcpue, wtcpue, numh, wgth, num, wgt, Length, numlencpue, numlenh,
numlencpue_q,numlenh_q)
detach(package:worms)
detach(package:plyr)
# 1. associate an LME to each haul and make final list of species
### Prepare list for estimating length-weight parameters
list.taxa <- survey %>%
select(HaulID, Survey, ShootLat, ShootLong, Family, Genus, Species) %>%
distinct()
# get LME
library(rgdal)
shape1 <- readOGR(dsn = "data/LME shapefile",layer="lme66")
coords <- list.taxa %>%
dplyr::select(ShootLat, ShootLong, Survey) %>%
distinct()
str(coords)
coordinates(coords) <- ~ ShootLong + ShootLat
proj4string(coords) <- proj4string(shape1)
lme <- over(coords, shape1)
coords <- list.taxa %>%
dplyr::select(ShootLat, ShootLong, Survey) %>%
distinct()
coords <- cbind(coords, lme$LME_NUMBER)
setnames(coords, old='lme$LME_NUMBER', new='lme')
# plot
# ggplot(coords,aes(ShootLong,ShootLat))+
#   borders('world', xlim=c(-90,50), ylim=c(25,85), fill='black', colour='black') +
#   coord_quickmap(xlim=c(-90,50), ylim=c(25,85))+
#   geom_polygon(data=shape1, aes(y=lat, x=long, group=group), fill='lightgrey', colour='black')+
#   theme_bw()+xlab('')+ylab('')+
#   geom_point(cex = 0.2, colour='blue')
coords$lme <- as.factor(coords$lme)
#Select from each LME 50 long and lat
ind <- c()
for (i in 1:nlevels(coords$lme)){
ind <- c(ind, sample(which(coords$lme==levels(coords$lme)[i]), 50, replace = FALSE))
}
long50 <- coords$ShootLong[ind]
lat50 <- coords$ShootLat[ind]
lme50 <- rep(levels(coords$lme), each=50)
#For each haul without LME find a close LME that has an LME number already
nlme <- subset(coords, is.na(lme)) # many hauls without LME 710
nlme$ShootLat <- as.numeric(as.vector(nlme$ShootLat))
nlme$ShootLong <- as.numeric(as.vector(nlme$ShootLong))
long50 <- as.numeric(as.vector(long50))
lat50 <- as.numeric(as.vector(lat50))
dilme <- c()
for (i in 1:length(lme50)){
dilme <- cbind(dilme, (nlme$ShootLat-lat50[i])**2 + (nlme$ShootLong-long50[i])**2)
}
mindi <- apply(dilme, 1, which.min)
coords$lme[is.na(coords$lme)] <- lme50[mindi] # assign the closest LME number to each haul without LME
#Check
coords$ShootLat <- as.numeric(as.vector(coords$ShootLat))
coords$ShootLong <- as.numeric(as.vector(coords$ShootLong))
# rockall not assigned to Faroe plateau but to celtic sea LME
coords$lme <- as.character(coords$lme)
coords <- coords %>%
mutate(lme = replace(lme, Survey  =='ROCKALL', '60')) %>%
as.data.frame()
#plot(coords$ShootLong, coords$ShootLat, col=rainbow(length(unique(coords$lme)))[as.factor(coords$lme)], pch=".")
survey <- left_join(survey, coords, by=c('ShootLat', 'ShootLong','Survey'))
survey <- survey %>% filter(Species!='Gobioidei')
# this was run before cephalopods - it is used to get a LxW relationship for
# each LME; this information has not been updated for the cephalopod code
# a fixed lenght x weight is used for all cephalopods
# library(tidyverse)
# list.taxa <- survey %>%
#  select(Family, Genus, Species, lme) %>%
# distinct() %>%
#  mutate(fao = 27,
#         Subspecies = str_split(Species, pattern = " ", simplify=T)[,3],
#         Species = str_split(Species, pattern = " ", simplify=T)[,2],
#        Species = if_else(Subspecies!="", paste(Species, Subspecies, sep=" "), Species))
#write.csv(data.frame(list.taxa), file="traits and species/taxa.DATRAS.FB.tofill5.csv", row.names=FALSE)
#save(survey, file = "data/DATRAS_before_lw_xxxxx.RData") # could save intermediate stage
# 2. re-calculate weights with length-weight relationships
datalw <- read.csv('traits and species/taxa.DATRAS.FB_filled5.csv') %>%
mutate(Taxon = case_when(level=='family' ~ family,
level=='genus' ~ genus,
level=='species' ~ paste(genus, species, sep=" ")),
lme = as.factor(lme)) %>%
select(-fao,-family,-genus,-species)
ceph_q <- cbind(ceph_q,survey[match(ceph_q$AphiaID,survey$AphiaID),c("Species")])
colnames(ceph_q)[ncol(ceph_q)] <- "Taxon"
datalw_ceph <- data.frame(lme=1000,level="species",FB_E_Code=NA,source=NA,type.length=NA,
taxo=NA,b=3,a=0.01,Taxon=ceph_q$Taxon)
datalw_ceph$lme <- as.factor(datalw_ceph$lme)
datalw <- rbind(as.data.frame(datalw),datalw_ceph)
survey <- survey %>%
mutate(Taxon = case_when(is.na(Species) & is.na(Genus) ~ Family,
Species=="" & is.na(Genus) ~ Family,
is.na(Species) & !is.na(Genus) ~ Genus,
Species=="" & !is.na(Genus) ~ Genus,
!is.na(Species) ~ Species))
survey[survey$Species=='Syngnatus',]$Taxon <- 'Syngnathus'
survey[survey$Species=='Syngnatus',]$Species <- 'Syngnathus'
# now change lme for each cephalopoda
survey$lme[survey$AphiaID %in% ceph_q$AphiaID] <- 1000
# summarize abundance/weight at the haul level
survey.num <- left_join(survey, datalw, by=c('Taxon','lme')) %>%
select(Survey,HaulID,StatRec,Year,Month,Quarter,Season,ShootLat,ShootLong,HaulDur,Area.swept,Area.doors,Gear,Depth,SBT,SST,Family,Genus,Species,Taxon,
CatIdentifier,numcpue,numh,num) %>%
distinct() %>%
group_by(Survey,HaulID,StatRec,Year,Month,Quarter,Season,ShootLat,ShootLong,HaulDur,Area.swept,Area.doors,Gear,Depth,SBT,SST,Family,Genus,Species,Taxon) %>%
summarize_at(.vars=c('numcpue', 'numh', 'num'), .funs = function(x) sum(x)) %>%
ungroup()
survey.wgt <- left_join(survey, datalw, by=c('Taxon','lme')) %>%
select(Survey,HaulID,StatRec,Year,Month,Quarter,Season,ShootLat,ShootLong,HaulDur,Area.swept,Area.doors,Gear,Depth,SBT,SST,Family,Genus,Species,Taxon,
CatIdentifier,wtcpue,wgth,wgt) %>%
distinct() %>%
group_by(Survey,HaulID,StatRec,Year,Month,Quarter,Season,ShootLat,ShootLong,HaulDur,Area.swept,Area.doors,Gear,Depth,SBT,SST,Family,Genus,Species,Taxon) %>%
summarize_at(.vars=c('wtcpue', 'wgth', 'wgt'), .funs = function(x) sum(x)) %>%
ungroup()
survey1 <- full_join(survey.num, survey.wgt,
by=c('Survey','HaulID','StatRec','Year','Month','Quarter',
'Season','ShootLat','ShootLong','HaulDur','Area.swept','Area.doors',
'Gear','Depth','SBT','SST','Family','Genus','Species','Taxon'))
# summarize abundance/weight from length data
survey2 <- left_join(survey, datalw, by=c('Taxon','lme')) %>%
mutate(wgtlencpue = numlencpue*a*Length^b/1000, # divide by 1000 to get kg/km2
wgtlenh = numlenh*a*Length^b/1000, # divide by 1000 to get kg/h
wgtlencpue_q = numlencpue_q*a*Length^b/1000, # divide by 1000 to get kg/km2
wgtlenh_q = numlenh_q*a*Length^b/1000) %>% # divide by 1000 to get kg/h
group_by(Survey,HaulID,StatRec,Year,Month,Quarter,Season,ShootLat,ShootLong,HaulDur,Area.swept,Area.doors,Gear,Depth,SBT,SST,Family,Genus,Species,Taxon, a, b) %>%
summarize_at(.vars=c('numlencpue','numlenh','wgtlencpue','wgtlenh','numlencpue_q','numlenh_q','wgtlencpue_q','wgtlenh_q'), .funs=function(x) sum(x)) %>%
ungroup()
# merge both and compare
nrow(survey1)==nrow(survey2)
survey3 <- full_join(survey1, survey2, by=c('Survey','HaulID','StatRec','Year','Month','Quarter','Season','ShootLat','ShootLong','HaulDur',
'Area.swept','Area.doors','Gear','Depth','SBT','SST','Family','Genus','Species','Taxon'))
library(ggplot2)
# correlation between abundances to check calculations are right
cor(x = survey3$numh, y = survey3$numlenh, method = 'pearson')
xx <- subset(survey3, !is.na(numcpue))
cor(x = xx$numcpue, y = xx$numlencpue, method = 'pearson')
# check weights
xx <- subset(survey3, wtcpue   >0 & wgtlencpue>0)
cor(x = xx$wtcpue , y = xx$wgtlencpue, method = 'pearson')
xx <- subset(survey3, wgth>0 & wgtlenh>0)
cor(x = xx$wgth, y = xx$wgtlenh, method = 'pearson')
# no zeros
xx <- subset(survey3, wgth>0 & wgtlenh>0)
# rockall looks OK
ggplot(subset(xx, Survey=='ROCKALL'), aes(x=wgth, y=wgtlenh)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
# IE-IGFS looks OK
ggplot(subset(xx, Survey=='IE-IGFS'), aes(x=wgth, y=wgtlenh)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
# NIGFS looks OK
ggplot(subset(xx, Survey=='NIGFS'), aes(x=wgth, y=wgtlenh)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
# PT-IBTS looks OK
ggplot(subset(xx, Survey=='PT-IBTS'), aes(x=wgth, y=wgtlenh)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
# FR-CGFS looks OK
ggplot(subset(xx, Survey=='FR-CGFS'), aes(x=wgth, y=wgtlenh)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
# Can-MARS looks OK
ggplot(subset(xx, Survey=='Can-Mar'), aes(x=wgth, y=wgtlenh)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
# SWC-IBTS issue
ggplot(subset(xx, Survey=='SWC-IBTS'), aes(x=wgth, y=wgtlenh)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
comp <- subset(xx, Survey=='SWC-IBTS') %>%
select(HaulID,wgtlenh,wgth) %>%
distinct() %>%
group_by(HaulID) %>%
summarize_at(.vars=c('wgtlenh', 'wgth'), .funs = function(x) sum(x)) %>%
ungroup() %>%
as.data.frame()
ggplot(comp, aes(x=wgth, y=wgtlenh)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
comp$factor <-   comp$wgtlenh / comp$wgth
plot(comp$factor)
resc <- comp$HaulID[comp$factor > 40]
# after check with original haul length data (HL) for some resc haulid, weight is clearly wrong factor 100
survey3 <- survey3 %>%
mutate(wtcpue = if_else(HaulID %in% resc, wtcpue*100,wtcpue),
wgth = if_else(HaulID %in% resc , wgth*100,wgth),
wgt = if_else(HaulID %in% resc , wgt*100,wgt))
# BITS issue
ggplot(subset(xx, Survey=='BITS'), aes(x=wgth, y=wgtlenh)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
comp <- subset(xx, Survey=='BITS') %>%
select(HaulID,wgtlenh,wgth) %>%
distinct() %>%
group_by(HaulID) %>%
summarize_at(.vars=c('wgtlenh', 'wgth'), .funs = function(x) sum(x)) %>%
ungroup() %>%
as.data.frame()
ggplot(comp, aes(x=wgth, y=wgtlenh)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
comp$factor <-   comp$wgtlenh / comp$wgth
plot(comp$factor)
resc <- comp$HaulID[comp$factor > 40]
# after check with original haul length data (HL) for some resc haulid, weight is clearly wrong factor 100
survey3 <- survey3 %>%
mutate(wtcpue = if_else(HaulID %in% resc, wtcpue*100,wtcpue),
wgth = if_else(HaulID %in% resc , wgth*100,wgth),
wgt = if_else(HaulID %in% resc , wgt*100,wgt))
# EVHOE may have an issue, no changes as not very clear
ggplot(subset(xx, Survey=='EVHOE'), aes(x=wgth, y=wgtlenh)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
comp <- subset(xx, Survey=='EVHOE') %>%
select(HaulID,wgtlenh,wgth) %>%
distinct() %>%
group_by(HaulID) %>%
summarize_at(.vars=c('wgtlenh', 'wgth'), .funs = function(x) sum(x)) %>%
ungroup() %>%
as.data.frame()
ggplot(comp, aes(x=wgth, y=wgtlenh)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
comp$factor <-   comp$wgtlenh / comp$wgth
plot(comp$factor)
# NS - IBTS issue
ggplot(subset(xx, Survey=='NS-IBTS'), aes(x=wgth, y=wgtlenh)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
comp <- subset(xx, Survey=='NS-IBTS') %>%
select(HaulID,wgtlenh,wgth) %>%
distinct() %>%
group_by(HaulID) %>%
summarize_at(.vars=c('wgtlenh', 'wgth'), .funs = function(x) sum(x)) %>%
ungroup() %>%
as.data.frame()
ggplot(comp, aes(x=wgth, y=wgtlenh)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
comp$factor <-   comp$wgtlenh / comp$wgth
comp$uni <- c(1:nrow(comp))
plot(comp$factor~comp$uni,ylim=c(0,120))
points(comp$factor[comp$factor > 20]~comp$uni[comp$factor > 20],col="red")
points(comp$factor[comp$factor > 8 & comp$factor <20]~comp$uni[comp$factor  > 8 & comp$factor <20],col="blue")
# two issues - one estimate 100 times higher based on length, the other 10 times
resc <- comp$HaulID[comp$factor > 20]
resc2 <- comp$HaulID[comp$factor > 8 & comp$factor <20]
# after check with original haul length data (HL) for some resc haulid, weight is clearly wrong factor 100
# and also a cluster of factor 10
survey3 <- survey3 %>%
mutate(wtcpue = if_else(HaulID %in% resc, wtcpue*100,wtcpue),
wgth = if_else(HaulID %in% resc , wgth*100,wgth),
wgt = if_else(HaulID %in% resc , wgt*100,wgt))
survey3 <- survey3 %>%
mutate(wtcpue = if_else(HaulID %in% resc2, wtcpue*10,wtcpue),
wgth = if_else(HaulID %in% resc2 , wgth*10,wgth),
wgt = if_else(HaulID %in% resc2 , wgt*10,wgt))
# check again correlations
xx <- subset(survey3, wtcpue> 0 & wgtlencpue>0)
cor(x = xx$wtcpue , y = xx$wgtlencpue, method = 'pearson') # is (a bit) better
xx <- subset(survey3, wgth>0 & wgtlenh>0)
cor(x = xx$wgth, y = xx$wgtlenh, method = 'pearson') # is (a bit) better
# now check per haul without zeros, NAs
xx <- subset(survey3, wtcpue>0 & wgtlencpue>0)
comp <- xx %>%
select(HaulID,wgtlencpue,wtcpue) %>%
distinct() %>%
group_by(HaulID) %>%
summarize_at(.vars=c('wgtlencpue', 'wtcpue'), .funs = function(x) sum(x)) %>%
ungroup() %>%
as.data.frame()
ggplot(comp, aes(x=wtcpue, y=wgtlencpue)) + geom_point() +
geom_abline(intercept = 0, slope = 1, color="red",
linetype="dashed", size=0.5) + scale_x_log10() + scale_y_log10()
cor(x = xx$wtcpue , y = xx$wgtlencpue, method = 'pearson')
##########################################################################################
#### SAVE DATA
##########################################################################################
survey3 <- survey3 %>%
select(-num, -wgt) %>%
as.data.frame()
survey3 <- cbind(survey3,survey[match(survey3$Taxon,survey$Taxon),c("AphiaID")])
colnames(survey3)[ncol(survey3)] <- "AphiaID"
survey3 <- cbind(survey3,my_sp_taxo[match(survey3$AphiaID,my_sp_taxo$AphiaID),c("class")])
colnames(survey3)[ncol(survey3)] <- "class"
head(survey3)
save(survey3, file='cleaned data/ICESsurveys30Nov_withq_ceph.RData')
sef <- subset(survey3,survey3$class =="Cephalopoda")
dr <- aggregate(sef$wgtlencpue_q,by=list(sef$HaulID,sef$ShootLong,sef$ShootLat),FUN=sum,na.rm=T)
head(sef)
dr$x[dr$x>100] <- 100
ggplot() + geom_point(data=dr,aes(Group.2,Group.3,color=x))
dr <- aggregate(sef$wgtlencpue_q,by=list(sef$HaulID,sef$ShootLong,sef$ShootLat),FUN=sum,na.rm=T)
dr$x[dr$x>500] <- 500
ggplot() + geom_point(data=dr,aes(Group.2,Group.3,color=x))
dr <- aggregate(sef$wgtlencpue_q,by=list(sef$HaulID,sef$ShootLong,sef$ShootLat),FUN=sum,na.rm=T)
dr$x[dr$x>800] <- 800
ggplot() + geom_point(data=dr,aes(Group.2,Group.3,color=x))
# and add folder to specific location
ram <- readRDS(paste(getwd(),'_noGIT/ramlegacy/4.44/RLSADB v4.44/DB Files With Assessment Data/v4.44.rds',sep=""))
# get estimate of area overlap between stock assessments and survey area
load("cleaned data/overlap_stockass_survey_area.RData")
colnames(final) <- c("areanb","overlap","name") # to simplify script
# now find all regions that overlap a large part of their area with the surveyed area in the ocean
fin <- subset(final,final$overlap > 0.3)
# select all stocks
stock <- ram$stock
stock <- subset(stock,stock$areaid %in% fin$name)
stock <- cbind(stock,fin[match(stock$areaid,fin$name),c(2)])
colnames(stock)[ncol(stock)] <- "overlap"
names(ram)
# get their average biomass between 2005 and 2009
ramdata   <- ram$timeseries_values_views
head(ramdata)
# get their average biomass between 2005 and 2009
ramdata   <- ram$timeseries_values_views
ramunits  <- ram$timeseries_units_views
rammethod <- ram$assessment
stock$SSB <- NA ;stock$SSB_units <- NA
stock$TB  <- NA ;stock$TB_units <- NA
stock$TC  <- NA ;stock$TC_units <- NA
stock$TL  <- NA ;stock$TL_units <- NA
stock$assessmethod <- NA
names(ram)
ram$bioparams
head(ram$bioparams)
head(ram$assessment)
head(ram$timeseries_values_views)
# get their average biomass between 2005 and 2009
ramdata   <- ram$timeseries_values_views
ramunits  <- ram$timeseries_units_views
rammethod <- ram$assessment
stock$SSB <- NA ;stock$SSB_units <- NA
stock$TB  <- NA ;stock$TB_units <- NA
stock$TC  <- NA ;stock$TC_units <- NA
stock$TL  <- NA ;stock$TL_units <- NA
stock$TAC <- NA ;stock$TAC_units <- NA
stock$ER  <- NA ;stock$ER_units <- NA
stock$assessmethod <- NA
for(j in 1:nrow(stock)){
# get biomass
spec <- subset(ramdata,ramdata$stockid == stock$stockid[j] & ramdata$year %in% c(2000:2005))
stock$SSB[j] <- mean(spec$SSB,na.rm=T)
stock$TB[j]  <- mean(spec$TB,na.rm=T)
stock$TC[j]  <- mean(spec$TC,na.rm=T)
stock$TL[j]  <- mean(spec$TL,na.rm=T)
stock$TAC[j]  <- mean(spec$TAC,na.rm=T)
stock$ER[j]  <- mean(spec$ER,na.rm=T)
# get units
if (nrow(spec)>0){
specunits <- subset(ramunits,ramunits$stockid == stock$stockid[j])
stock$SSB_units[j] <- specunits$SSB
stock$TB_units[j]  <- specunits$TB
stock$TC_units[j]  <- specunits$TC
stock$TL_units[j]  <- specunits$TL
stock$TAC_units[j]  <- specunits$TAC
stock$ER_units[j]  <- specunits$ER
stock_method <- subset(rammethod,rammethod$stockid == stock$stockid[j] & rammethod$mostrecent == 999)
stock$assessmethod[j] <- stock_method$assessmethod
}}
head(stock)
setwd("C:/Users/danie")
write.csv(stock,file="stock_to_check.csv",row.names = F)
j <- 1
stock$stockid[j]
stock$stockid[2]
stock$stockid[4]
stock$stockid[10]
stock$stockid[5]
stock$stockid
j <- 72
spec <- subset(ramdata,ramdata$stockid == stock$stockid[j])
spec
stock$stockid[j]
# get their average biomass between 2005 and 2009
ramdata   <- ram$timeseries_values_views
ramunits  <- ram$timeseries_units_views
rammethod <- ram$assessment
stock$SSB <- NA ;stock$SSB_units <- NA
stock$TB  <- NA ;stock$TB_units <- NA
stock$TC  <- NA ;stock$TC_units <- NA
stock$TL  <- NA ;stock$TL_units <- NA
stock$TAC <- NA ;stock$TAC_units <- NA
stock$ER  <- NA ;stock$ER_units <- NA
stock$assessmethod <- NA
spec <- subset(ramdata,ramdata$stockid == stock$stockid[j])
spec <- subset(ramdata,ramdata$stockid == stock$stockid[1])
plot(spec)
plot(spec$TB)
plot(spec$SSB)
plot(spec$FdivFmgt
)
head(spec)
plot(spec$FdivFmsy)
library(raster)
library(sf)
library(sp)
# only first time
str_name<-'C:/Users/danie/Dropbox/Werk/MC paper 3/Data/landscan-global-2010-assets/landscan-global-2010.tif'
pop <- raster(str_name)
dim(pop)
20880/3
43200/3
r_hr <- raster(nrow=20880, ncol=43200)
r_hr[]<- pop
r_hr[]<- pop[[3]]
r_hr[]<- pop
values(pop) <- 1:ncell(pop)
?extent
e <- extent(80,180, 19, 90)
rc <- crop(r, e)
popc <- crop(pop, e)
dim(popc)
r_hr <- raster(nrow=7800, ncol=12000)
r_hr[]<- popc
r_hr[]<- as.matrix(popc)
r_lr <- raster(nrow=7800/4, ncol=12000/4)
r_lr<-resample(r_hr,r_lr, method="bilinear")
lattice::levelplot(r_lr)
de <- matrix(r_lr@data@values,ncol=7800/4,nrow=12000/4)
lattice::levelplot(de
)
# only first time
str_name<-'C:/Users/danie/Dropbox/Werk/MC paper 3/Data/landscan-global-2010-assets/landscan-global-2010.tif'
pop <- raster(str_name)
values(pop) <- 1:ncell(pop)
dim(pop)
r_hr <- raster(nrow=20880, ncol=43200)
r_hr[]<- as.matrix(pop)
r_lr <- raster(nrow=20880/12, ncol=43200/12)
r_lr<-resample(r_hr,r_lr, method="bilinear")
